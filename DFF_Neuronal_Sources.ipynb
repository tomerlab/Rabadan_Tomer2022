{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for calculating dF/F for identified neuronal activity sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@uthor: Raju Tomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import glob\n",
    "\n",
    "import monnet_utils as tl\n",
    "\n",
    "import skimage.external.tifffile as tff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import re\n",
    "import pickle\n",
    "import scipy as spy\n",
    "from scipy import ndimage as ndi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "prefix_swap_sw = False\n",
    "\n",
    "analysis_dir = r'X:\\People\\Raju\\Batch06a'\n",
    "data_dir = r'Y:\\Data'\n",
    "f_data_dir = r'fdata'\n",
    "dict_in_fn = tl.load_pickle(f_data_dir, r'dict_in_fn.pickle')\n",
    "dict_im_lab = tl.load_pickle(f_data_dir,  r'dict_im_lab.pickle')\n",
    "xsaZ\n",
    "for key in dict_in_fn.keys():\n",
    "        max_file_name = os.path.basename(dict_in_fn[key])\n",
    "        if ('MAX_' not in max_file_name):\n",
    "            max_file_name = 'MAX_' + max_file_name\n",
    "        dict_in_fn[key] = os.path.join(data_dir, max_file_name)\n",
    "        print(dict_in_fn[key])\n",
    "\n",
    "After treatment data\n",
    "dict_in_fn_AT = {}\n",
    "data_dir = r'Y:\\Data\\Aligned'\n",
    "\n",
    "file_names = sorted(glob.glob(os.path.join(data_dir, 'MAX_*.tif')))\n",
    "for i in range(0,len(file_names)):\n",
    "    dict_in_fn_AT[i] = file_names[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### to construct dict with key file names\n",
    "file_names_A = sorted(glob.glob(os.path.join(analysis_dir, 'cnm_A_key*')))\n",
    "print(file_names_A[0])\n",
    "dict_A_fn = tl.construct_fn_dict(file_names_A, key_extr_pat=r'.*cnm_A_key(\\d*)_(.*\\.tif)\\..*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_run = sorted(dict_A_fn.keys())\n",
    "print(to_run)\n",
    "to_run = to_run[0:]\n",
    "print(to_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#im_sz = (512,512)\n",
    "p_th = 75\n",
    "down_sample = False\n",
    "for k in to_run:\n",
    "    print(k,dict_in_fn[k])\n",
    "\n",
    "# Read image, iterate through slices\n",
    "    im_fname = dict_in_fn[k]\n",
    "    im_fname = im_fname.replace('MAX_','')\n",
    "    im_fname_AT = dict_in_fn_AT[k]\n",
    "    im_fname_AT = im_fname_AT.replace('MAX_','')\n",
    "    print(im_fname_AT)\n",
    "    im_st_fn = 'im_st_key' +  str(k) + '_' + os.path.basename(im_fname) + '.tif'\n",
    "        \n",
    "    print('\\nReading image file from: ', im_fname)\n",
    "    im = tff.imread(im_fname)\n",
    "    im_shape = im.shape\n",
    "    print('im', im.shape)\n",
    "    im_avg = np.mean(im,axis=0)\n",
    "    mask_bg = (dict_im_lab[k] < 1) & (im_avg > 0)\n",
    "    im_bg = np.median(im_avg[mask_bg])\n",
    "    im_bg = 0.9*im_bg\n",
    "    print('im_bg estimated as ', im_bg)\n",
    "\n",
    "    print('Loading A: ', dict_A_fn[k])\n",
    "    A = np.load(os.path.join(analysis_dir, dict_A_fn[k]))\n",
    "    dict_mask = {}\n",
    "    \n",
    "    im_sz = [im_shape[1], im_shape[2]]\n",
    "    \n",
    "    im_st = np.zeros((A.shape[1], im_sz[0], im_sz[1]), dtype='uint16')\n",
    "    print('im_st shape', im_st.shape)\n",
    "    print('Generating im_st with p_th of ', p_th)\n",
    "    for i in range(A.shape[1]):\n",
    "        Ai = np.copy(A[:,i])\n",
    "        Ai = Ai[Ai>0]\n",
    "        thr = np.percentile(Ai,p_th)\n",
    "        imt = np.reshape(A[:,i],im_sz, order='F')\n",
    "        im_thr = np.copy(imt)\n",
    "        im_thr[im_thr<thr] = 0\n",
    "        im_thr[im_thr>=thr] = i+1\n",
    "        im_st[i,:,:] = im_thr\n",
    "        dict_mask[i] = im_thr>0\n",
    "    print('Saving im_st as ', im_st_fn)\n",
    "    tff.imsave(os.path.join(analysis_dir,im_st_fn), im_st)\n",
    "\n",
    "        \n",
    "    if (down_sample):\n",
    "        im = downscale_local_mean(im, (2,1,1))\n",
    "        im_shape = im.shape\n",
    "        print('New im', im.shape)\n",
    "        \n",
    "#     im = np.concatenate((im, im_AT), axis=0)\n",
    "\n",
    "# process im\n",
    "    f_dat = np.zeros((A.shape[1], im.shape[0]), dtype='float')\n",
    "    print('Calculating mean fluorescence signal')\n",
    "    for z in range(im.shape[0]):\n",
    "        if (z%100==0):\n",
    "            print('z: ', z)\n",
    "#         print('im', im.shape)\n",
    "        z_slice = im[z,:,:]\n",
    "        for j in range(A.shape[1]):\n",
    "            f_dat[j,z] = np.mean(z_slice[dict_mask[j]])\n",
    "    f_dat = f_dat - im_bg\n",
    "    f_dat[f_dat<0] = 0\n",
    "    print('Adding a small number 2 to avoid divisions by zero in DFF calcs')\n",
    "    f_dat = f_dat + 2\n",
    "    print('Generating dff with perc 8 and win_sz 500')\n",
    "    dff_dat = tl.convert_f_to_dff_perc(f_dat, 8, win_sz=500)\n",
    "    \n",
    "    post_str = str(k) + '_' + os.path.basename(im_fname) + '.npy'    \n",
    "    f_fn = 'f_mean_key' +  post_str\n",
    "    dff_fn = 'dff_f_mean_key' +  post_str\n",
    "    print('Saving f and dff as ', f_fn, ' ', dff_fn)\n",
    "    np.save(os.path.join(analysis_dir,f_fn), f_dat)\n",
    "    np.save(os.path.join(analysis_dir,dff_fn), dff_dat)\n",
    "\n",
    "# process im_AT\n",
    "    print('\\nReading image file from: ', im_fname_AT)\n",
    "    im = tff.imread(im_fname_AT)\n",
    "    im_avg = np.mean(im,axis=0)\n",
    "    mask_bg = (dict_im_lab[k] < 1) & (im_avg > 0)\n",
    "    im_bg = np.median(im_avg[mask_bg])\n",
    "    im_bg = 0.9*im_bg\n",
    "    print('im_AT_bg estimated as ', im_bg)\n",
    "\n",
    "    if (down_sample):\n",
    "        im = downscale_local_mean(im, (2,1,1))\n",
    "        im_shape = im.shape\n",
    "        print('New im_AT', im.shape)\n",
    "    f_dat = np.zeros((A.shape[1], im.shape[0]), dtype='float')\n",
    "    print('AT Calculating mean fluorescence signal')\n",
    "    for z in range(im.shape[0]):\n",
    "        if (z%100==0):\n",
    "            print('z: ', z)\n",
    "        z_slice = im[z,:,:]\n",
    "        for j in range(A.shape[1]):\n",
    "            f_dat[j,z] = np.mean(z_slice[dict_mask[j]])\n",
    "    f_dat = f_dat - im_bg\n",
    "    f_dat[f_dat<0] = 0\n",
    "    print('Adding a small number 2 to avoid divisions by zero in DFF calcs')\n",
    "    f_dat = f_dat + 2\n",
    "    print('Generating dff with perc 8 and win_sz 500')\n",
    "    dff_dat = tl.convert_f_to_dff_perc(f_dat, 8, win_sz=500)\n",
    "    \n",
    "#     im_st_fn = 'im_AT_st_key' +  str(k) + '_' + os.path.basename(im_fname) + '.tif'\n",
    "#     print('Saving im_AT_st as ', im_st_fn)\n",
    "#     tff.imsave(os.path.join(analysis_dir,im_st_fn), im_st)\n",
    "#     post_str = str(k) + '_' + os.path.basename(im_fname) + '.npy'    \n",
    "    f_fn = 'f_AT_mean_key' +  post_str\n",
    "    dff_fn = 'dff_f_AT_mean_key' +  post_str\n",
    "    print('Saving f and dff as ', f_fn, ' ', dff_fn)\n",
    "    np.save(os.path.join(analysis_dir,f_fn), f_dat)\n",
    "    np.save(os.path.join(analysis_dir,dff_fn), dff_dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
