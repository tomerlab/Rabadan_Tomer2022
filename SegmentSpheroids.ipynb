{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code of semi-automated segmentation of spheroids in MoNNets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@uthor: Raju Tomer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as sk\n",
    "from skimage import io\n",
    "import skimage.external.tifffile as tff\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "import scipy as spy\n",
    "import skimage as sk\n",
    "import skimage.filters as skf\n",
    "import skimage.morphology as skm\n",
    "import skimage.measure as skmes\n",
    "import skimage.segmentation as sks\n",
    "import matplotlib.patches as mptch\n",
    "import scipy.io as sio\n",
    "import scipy as scpy\n",
    "import glob\n",
    "import skimage.transform as skt\n",
    "import pickle\n",
    "import scipy.signal as spy_sig\n",
    "from skimage import transform as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to segment\n",
    "def segment_nsps(im_use, marker_up=0.5, marker_low=0.5, sz_thres=100, clear_borders=False, vmin=1500, vmax=3000):\n",
    "    im_seg = np.multiply(ndi.gaussian_filter(im_use, sigma=2), 0.6) - np.multiply(ndi.gaussian_filter(im_use, sigma=20), 0.4)\n",
    "    im_seg[im_seg<0]=0\n",
    "    th = skf.threshold_isodata(im_seg)\n",
    "    print(th)\n",
    "    elevation_map = sk.filters.sobel(im_seg)\n",
    "    markers = np.zeros_like(im_seg)\n",
    "    markers[im_seg <= marker_low*th] = 1\n",
    "    markers[im_seg > marker_up*th] = 2\n",
    "    seg = skm.watershed(elevation_map, markers)\n",
    "    seg = ndi.binary_fill_holes(seg - 1)\n",
    "    #seg = skm.opening(seg, skm.square(7))\n",
    "    seg = skm.closing(seg, skm.square(3))\n",
    "    if (clear_borders):\n",
    "        seg = sks.clear_border(seg)\n",
    "    label_objects, nr_labels = ndi.label(seg) # to remove small objects\n",
    "    sizes = np.bincount(label_objects.ravel())\n",
    "    mask_sizes = sizes > sz_thres\n",
    "    #print(sizes)\n",
    "    mask_sizes[0] = 0\n",
    "    seg_cleaned = mask_sizes[label_objects]\n",
    "    seg_cleaned = skm.erosion(seg_cleaned, skm.square(1))\n",
    "    #seg_cleaned = skm.erosion(seg_cleaned)\n",
    "    #seg_cleaned = skm.erosion(seg_cleaned,)\n",
    "    im_lab, tmp = ndi.label(seg_cleaned>0)\n",
    "\n",
    "    #print(im_lab.shape)\n",
    "    fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(12, 7), sharex=True, sharey=True)\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    ax[0].imshow(im_use, cmap=plt.cm.gray, interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "    ax[0].set_title('im_max')\n",
    "\n",
    "    ax[1].imshow(im_use, cmap=plt.cm.gray, interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "    ax[1].set_title('im_max')\n",
    "\n",
    "    ax[2].imshow(markers, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax[2].set_title('markers')\n",
    "\n",
    "    ax[3].imshow(seg, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax[3].set_title('seg')\n",
    "\n",
    "    ax[4].imshow(seg_cleaned, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    ax[4].set_title('seg_cleaned')\n",
    "\n",
    "    ax[5].imshow(im_lab, interpolation='nearest')\n",
    "    ax[5].set_title('im_lab')\n",
    "\n",
    "    for region in skmes.regionprops(im_lab):\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        rect = mptch.Rectangle((minc, minr), maxc - minc, maxr - minr, fill=False, edgecolor='red', linewidth=2)\n",
    "        ax[0].add_patch(rect)\n",
    "        c = region.centroid\n",
    "        ax[3].text(c[1].astype(int), c[0].astype(int), region['label'],bbox={'facecolor':'white', 'alpha':0.8, 'pad':5})\n",
    "    plt.show()\n",
    "    im_lab = im_lab.astype('uint16')\n",
    "    return im_lab\n",
    "\n",
    "def run_segmentation(from_key, till_key, dict_in_fn, dict_im_lab,\n",
    "                    clear_borders=True, marker_up=0.97, marker_low=0.97, sz_thres=80, vmin=1500, vmax=5000):\n",
    "    for key in dict_in_fn.keys():\n",
    "        if ((key >= from_key) & (key <= till_key)):\n",
    "            print('###################')\n",
    "            print('dict_key =', key)\n",
    "            print(dict_in_fn[key])\n",
    "            im_max = tff.imread(os.path.join(dict_in_fn[key]))\n",
    "            print(im_max.shape)\n",
    "            dict_im_lab[key] = np.copy(segment_nsps(im_use=np.copy(im_max), clear_borders=clear_borders, \n",
    "                                                    marker_up= marker_up, marker_low=marker_low, sz_thres=sz_thres, vmin=vmin, vmax=vmax))\n",
    "\n",
    "def remove_labels(to_remove, d_key, dict_im_lab, dict_in_fn, vmin=1500, vmax=3000):\n",
    "    im_l = np.copy(dict_im_lab[d_key])\n",
    "    for k in range(len(to_remove)):\n",
    "        im_l[im_l==to_remove[k]] = 0\n",
    "    im_l, tmp = ndi.label(im_l>0)\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(12, 7), sharex=True, sharey=True)\n",
    "    ax = axes.ravel()\n",
    "    im_m = tff.imread(dict_in_fn[d_key])\n",
    "    ax[0].imshow(im_m, cmap=plt.cm.gray, interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "    ax[0].set_title('im_max')\n",
    "\n",
    "    ax[1].imshow(im_m, cmap=plt.cm.gray, interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "    ax[1].set_title('im_max')\n",
    "\n",
    "    ax[2].imshow(im_l>0, interpolation='nearest')\n",
    "    ax[2].set_title('fixed seg')\n",
    "\n",
    "    ax[3].imshow(im_l, interpolation='nearest')\n",
    "    ax[3].set_title('fixed im_lab')\n",
    "\n",
    "    for region in skmes.regionprops(im_l):\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        rect = mptch.Rectangle((minc, minr), maxc - minc, maxr - minr, fill=False, edgecolor='red', linewidth=2)\n",
    "        ax[0].add_patch(rect)\n",
    "        c = region.centroid\n",
    "        ax[2].text(c[1].astype(int), c[0].astype(int), region['label'],bbox={'facecolor':'white', 'alpha':0.8, 'pad':5})\n",
    "    plt.show()\n",
    "    return im_l\n",
    "\n",
    "def calc_mean_f(im, im_lab):\n",
    "    index = np.unique(im_lab)\n",
    "    index = index[1:]\n",
    "    f_NSp = np.zeros((index.shape[0], im.shape[0]), dtype=float)\n",
    "    for i in range(im.shape[0]):\n",
    "        t = np.copy(im[i,:,:])\n",
    "        bg_sig = t[im_lab==0]\n",
    "        bg = np.mean(bg_sig[:])\n",
    "        t = t - bg\n",
    "        t[t<0] = 0\n",
    "        f_NSp[:,i] = ndi.mean(t, labels=im_lab, index=index)\n",
    "    return f_NSp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize dictionary variables\n",
    "dict_im_lab = {} #labelled image data, indexed by \"key\"\n",
    "dict_in_fn = {} #input file paths\n",
    "dict_out_fn = {} #output file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################\n",
      "dict_key = 0\n",
      "MAX_211222_D1WB_bs_DIV15_crp_moco_Red4x.tif\n",
      "###################\n",
      "dict_key = 1\n",
      "MAX_211222_D1WC_bs_DIV15_crp_moco_4xRed.tif\n",
      "###################\n",
      "dict_key = 2\n",
      "MAX_211222_D2WA_bs_DIV15_crp_moco_Red4x.tif\n",
      "###################\n",
      "dict_key = 3\n",
      "MAX_211222_D2WD_bs_DIV15_crp_moco_Red4x.tif\n",
      "###################\n",
      "dict_key = 4\n",
      "MAX_211222_D3WA_bs_DIV15_crp_Red4x.tif\n",
      "###################\n",
      "dict_key = 5\n",
      "MAX_211222_D3WD_bs_DIV15_crp_moco_Red4x.tif\n",
      "###################\n",
      "dict_key = 6\n",
      "MAX_211222_D4WA_bs_DIV15_crp_moco_Red4x.tif\n",
      "###################\n",
      "dict_key = 7\n",
      "MAX_211222_D4WB_bs_DIV15_crp_moco_Red4x.tif\n",
      "###################\n",
      "dict_key = 8\n",
      "MAX_211222_D4WD_bs_DIV15_moco_crp_Red4x.tif\n",
      "###################\n",
      "dict_key = 9\n",
      "MAX_211222_D5WB_bs_DIV15_crp_moco_Red4x.tif\n",
      "###################\n",
      "dict_key = 10\n",
      "MAX_211222_D5WC_bs_DIV15_crp_moco_Red4x.tif\n",
      "###################\n",
      "dict_key = 11\n",
      "MAX_211222_D6WA_bs_DIV15_crp_moco_Red4x.tif\n",
      "###################\n",
      "dict_key = 12\n",
      "MAX_211222_D6WD_bs_DIV15_crp_moco_Red4x.tif\n",
      "###################\n",
      "dict_key = 13\n",
      "MAX_211222_D7WA_bs_DIV15_crp_moco_Red4x.tif\n",
      "###################\n",
      "dict_key = 14\n",
      "MAX_211222_D7WB_bs_DIV15_crp_moco_Red4x.tif\n",
      "###################\n",
      "dict_key = 15\n",
      "MAX_211222_D7WD_bs_DIV15_moco_crp_Red4x.tif\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# Read all the file names (Max projection images generated by GenMaxProj.ipynb) into dict\n",
    "# Main directory containing all DIV folders\n",
    "rootdir = r'E:\\Raju\\MoNNet\\BT'\n",
    "i=-1\n",
    "for root2, dirs2, files2 in os.walk(rootdir):\n",
    "    for fn in sorted(files2):\n",
    "        if ('MAX_' in fn):\n",
    "            i = i+1\n",
    "            print('###################')\n",
    "            print('dict_key =', i)\n",
    "            print(fn)\n",
    "            dict_in_fn[i] = os.path.join(rootdir, fn)\n",
    "            t = fn.replace('MAX_', '')\n",
    "            dict_out_fn[i] = os.path.join(rootdir, 'im_lab_' + t)\n",
    "            #im_max = tff.imread(os.path.join(rootdir, dn, fn))\n",
    "            #dict_im_lab[i] = np.copy(segment_nsps(im_max, clear_borders=True, marker_up=0.97, marker_low=0.97, sz_thres=80, vmax=5000))\n",
    "print(len(dict_in_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### do for all keys and manually validate / adjust parameters\n",
    "from_key = 0\n",
    "till_key = 15\n",
    "run_segmentation(from_key, till_key, dict_in_fn, dict_im_lab,\n",
    "                    clear_borders=True, marker_up=1., marker_low=.8, sz_thres=85, vmin=1500, vmax=19000)\n",
    "\n",
    "d_key = from_key\n",
    "\n",
    "## the below code is to remove any labelled objects\n",
    "\n",
    "# to_remove = (1,3,22,4,13,18,19,21,20)\n",
    "# vmax=5000\n",
    "# dict_im_lab[d_key] = remove_labels(to_remove, d_key, dict_im_lab, dict_in_fn, vmax=vmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for storing all F value extractions\n",
    "dict_f_NsP = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate F values\n",
    "for key in dict_out_fn.keys():\n",
    "    try:\n",
    "        print('key:', key, ', FN:', dict_out_fn[key])\n",
    "        fn = dict_out_fn[key]\n",
    "        fn = fn.replace('\\\\im_lab_', '\\\\')\n",
    "        im = tff.imread(fn)\n",
    "        dict_f_NsP[key] = calc_mean_f(im, dict_im_lab[key])\n",
    "    except:\n",
    "        print('Error in Key: ', key, '  FN: ', fn)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##save files\n",
    "var_fn = r'X:\\People\\Raju\\Data\\dict_f_NsP_BT.pickle'\n",
    "pickle_out = open(var_fn,\"wb\")\n",
    "pickle.dump(dict_f_NsP, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "var_fn = r'X:\\People\\Raju\\Data\\dict_im_lab_BT.pickle'\n",
    "pickle_out = open(var_fn,\"wb\")\n",
    "pickle.dump(dict_im_lab, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "var_fn = r'X:\\People\\Raju\\Data\\dict_in_fn_BT.pickle'\n",
    "pickle_out = open(var_fn,\"wb\")\n",
    "pickle.dump(dict_in_fn, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize variables for after treatment aligned images (done with Registration notebook)\n",
    "dict_in_fn_AT = {}\n",
    "dict_out_fn_AT = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the file names into dict\n",
    "\n",
    "# Main directory containing all DIV folders\n",
    "rootdir = r'E:\\Raju\\MoNNet\\AT_aln'\n",
    "i=-1\n",
    "for root2, dirs2, files2 in os.walk(rootdir):\n",
    "    for fn in sorted(files2):\n",
    "        if ('MAX_' in fn):\n",
    "            i = i+1\n",
    "            print('###################')\n",
    "            print('dict_key =', i)\n",
    "            print(fn)\n",
    "            dict_in_fn_AT[i] = os.path.join(rootdir, fn)\n",
    "            t = fn.replace('MAX_', '')\n",
    "            dict_out_fn_AT[i] = os.path.join(rootdir, 'im_lab_' + t)\n",
    "print(len(dict_in_fn_AT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_f_NsP_AT = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate F values\n",
    "for key in dict_out_fn_AT.keys():\n",
    "    try:\n",
    "        print('key:', key, ', FN:', dict_out_fn_AT[key])\n",
    "        fn = dict_out_fn_AT[key]\n",
    "        fn = fn.replace('\\\\im_lab_', '\\\\')\n",
    "        im = tff.imread(fn)\n",
    "        dict_f_NsP_AT[key] = calc_mean_f(im, dict_im_lab[key])\n",
    "    except:\n",
    "        print('Error in Key: ', key, '  FN: ', fn)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dict_f_NsP_AT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_fn = r'X:\\People\\Raju\\Data\\dict_f_NsP_AT.pickle'\n",
    "pickle_out = open(var_fn,\"wb\")\n",
    "pickle.dump(dict_f_NsP_AT, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "var_fn = r'X:\\People\\Raju\\Data\\dict_in_fn_AT.pickle'\n",
    "pickle_out = open(var_fn,\"wb\")\n",
    "pickle.dump(dict_in_fn_AT, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
