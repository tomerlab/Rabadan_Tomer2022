{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code of activity source extraction from Ca2+ imaging data time stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@uthor: Raju Tomer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import skimage.external.tifffile as tff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import caiman as cm\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour, inspect_correlation_pnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "def load_pickle(d_dir,fn):\n",
    "    pickle_in = open(os.path.join(d_dir,fn),'rb')\n",
    "    dict_d = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    return dict_d\n",
    "\n",
    "\n",
    "prefix_swap_sw = False\n",
    "\n",
    "## Batch 07\n",
    "data_dir = r'Y:\\Data\\C57'\n",
    "f_data_dir = r'Y:\\Data\\C57\\Results'\n",
    "\n",
    "dict_f_NsP = load_pickle(f_data_dir, r'dict_f_Sph.pickle')\n",
    "dict_im_lab = load_pickle(f_data_dir,  r'dict_im_lab.pickle')\n",
    "dict_in_fn = load_pickle(f_data_dir, r'dict_in_fn.pickle')\n",
    "\n",
    "print(dict_in_fn[0])\n",
    "if (prefix_swap_sw):\n",
    "    for key in dict_in_fn.keys():\n",
    "        max_file_name = os.path.basename(dict_in_fn[key])\n",
    "        div = os.path.basename(os.path.dirname(dict_in_fn[key]))\n",
    "        dict_in_fn[key] = os.path.join(data_dir, div, max_file_name)\n",
    "        print(dict_in_fn[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = r'E:\\Raju\\NSp\\tmp_dir'\n",
    "analysis_dir = r'X:\\People\\Raju\\Data\\C57\\LSTM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_run = list(dict_in_fn.keys())\n",
    "print(to_run)\n",
    "# to_run = to_run[0:10]\n",
    "# print(to_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_caiman(Y, dview, n_processes=24, frate = 30, gSig = 3, rf = 80):\n",
    "    print(Y.shape)\n",
    "    decay_time = 0.8                 \n",
    "    p = 1               \n",
    "    K = None            \n",
    "    gSiz = 4*gSig + 1 \n",
    "    stride_cnmf = gSiz + 5\n",
    "    merge_thresh = .7   \n",
    "    tsub = 1            \n",
    "    ssub = 1            \n",
    "    Ain = None          \n",
    "    low_rank_background = None\n",
    "    gnb = -1         \n",
    "    nb_patch = -1       \n",
    "    min_corr = .8\n",
    "    min_pnr = 10\n",
    "    ssub_B = 1\n",
    "    ring_size_factor = 1.4\n",
    "    min_SNR = 3           \n",
    "    r_values_min = 0.85   \n",
    "    cnm = cnmf.CNMF(n_processes=n_processes,\n",
    "                    method_init='corr_pnr',             \n",
    "                    k=K,\n",
    "                    gSig=(gSig, gSig),\n",
    "                    gSiz=(gSiz, gSiz),\n",
    "                    merge_thresh=merge_thresh,\n",
    "                    p=p,\n",
    "                    dview=dview,\n",
    "                    tsub=tsub,\n",
    "                    ssub=ssub,\n",
    "                    Ain=Ain,\n",
    "                    rf=rf,\n",
    "                    stride=stride_cnmf,\n",
    "                    only_init_patch=True,               \n",
    "                    gnb=gnb,\n",
    "                    nb_patch=nb_patch,\n",
    "                    method_deconvolution='oasis',       \n",
    "                    low_rank_background=low_rank_background,\n",
    "                    update_background_components=True,  \n",
    "                    min_corr=min_corr,\n",
    "                    min_pnr=min_pnr,\n",
    "                    normalize_init=False,               \n",
    "                    center_psf=True,                    \n",
    "                    ssub_B=ssub_B,\n",
    "                    ring_size_factor=ring_size_factor,\n",
    "                    del_duplicates=True,                \n",
    "                    border_pix=0)                 \n",
    "    print('Running cnm')\n",
    "    cnm.fit(Y)\n",
    "    return cnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_ipython().magic(u'matplotlib inline')\n",
    "print(to_run)\n",
    "for key in to_run:\n",
    "    f = open(os.path.join(analysis_dir,\"error_log.txt\"), \"a\")\n",
    "    tic = time.clock()\n",
    "    print(key,dict_in_fn[key])\n",
    "    im_lab = dict_im_lab[key]\n",
    "    im_fname = dict_in_fn[key]\n",
    "    im_fname = im_fname.replace('MAX_','')\n",
    "    print(im_fname)\n",
    "    im = tff.imread(im_fname)\n",
    "    print('im', im.shape)\n",
    "    im[im==0] = 10\n",
    "    if (os.path.exists(dict_in_fn[key])):\n",
    "        im_max = tff.imread(dict_in_fn[key])\n",
    "    else:\n",
    "        im_max = np.max(im,axis=0)\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    tmp_tmp_dir = os.path.join(tmp_dir, 'key_' + str(key) + '_' + str(np.random.random()))\n",
    "    os.mkdir(tmp_tmp_dir)\n",
    "    tmp_fname = os.path.join(tmp_tmp_dir, 'memfile_tmp' + str(np.random.random()) + '.tif')\n",
    "    tff.imsave(tmp_fname, im)\n",
    "    fname_new = cm.save_memmap([tmp_fname], base_name='memmap_', order = 'C')\n",
    "    if os.path.isfile(tmp_fname):\n",
    "        os.remove(tmp_fname)\n",
    "    else:\n",
    "        print(\"Temp File not found\")\n",
    "        \n",
    "    Yr, dims, T = cm.load_memmap(fname_new)\n",
    "    Y = Yr.T.reshape((T,) + dims, order='F')\n",
    "        \n",
    "    print('Generating Corr Image:')\n",
    "    gSig = 3\n",
    "    try:\n",
    "        if 'dview' in locals():\n",
    "            cm.stop_server(dview=dview)\n",
    "        c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "            backend='local', n_processes=None, single_thread=False)\n",
    "        cn_filter, pnr = cm.summary_images.correlation_pnr(Y, gSig=gSig, swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile\n",
    "        inspect_correlation_pnr(cn_filter, pnr)\n",
    "        plt.show()\n",
    "        print('Running cnm')\n",
    "        cnm = run_caiman(Y, dview=dview, n_processes=n_processes, frate = 30, gSig = gSig, rf = 40)\n",
    "        cm.stop_server(dview=dview)\n",
    "    except:\n",
    "        try:\n",
    "            cm.stop_server(dview=dview) # stop it if it was running\n",
    "        except:\n",
    "            pass\n",
    "        print('Error in', key)\n",
    "        f.write('\\nError in key ' + str(key))\n",
    "        f.close()\n",
    "        continue\n",
    "    try:\n",
    "        nb_view_patches(Yr, cnm.estimates.A.tocsc(), cnm.estimates.C,\n",
    "            cnm.estimates.b, cnm.estimates.f, dims[0], dims[1], YrA=cnm.estimates.YrA, image_neurons=cn_filter,\n",
    "            denoised_color='red', thr=0.8, cmap='gray')\n",
    "        post_str = str(key) + '_' + os.path.basename(im_fname) + '.npy'    \n",
    "        cnm_As_fn = 'cnm_A_key' +  post_str\n",
    "        np.save(os.path.join(analysis_dir,cnm_As_fn), cnm.estimates.A.todense())\n",
    "        cnm_C_fn = 'cnm_C_key' +  post_str\n",
    "        np.save(os.path.join(analysis_dir,cnm_C_fn), cnm.estimates.C)\n",
    "        cnm_S_fn = 'cnm_S_key' +  post_str\n",
    "        np.save(os.path.join(analysis_dir,cnm_S_fn), cnm.estimates.S)\n",
    "        cnm.save(os.path.join(analysis_dir,'cnm_Obj_key' +  post_str + '.hdf5'))    \n",
    "\n",
    "        # save data\n",
    "        cn_filter_fn =  'cn_filter_key' + post_str \n",
    "        pnr_filter_fn = 'pnr_filter_key' + post_str\n",
    "        np.save(os.path.join(analysis_dir,cn_filter_fn), cn_filter)\n",
    "        np.save(os.path.join(analysis_dir,pnr_filter_fn), pnr)\n",
    "        tff.imsave(os.path.join(analysis_dir,cn_filter_fn+'.tif'), cn_filter)\n",
    "        tff.imsave(os.path.join(analysis_dir,pnr_filter_fn+'.tif'), pnr)\n",
    "\n",
    "        toc = time.clock()\n",
    "        print('Time taken:', toc-tic)\n",
    "\n",
    "\n",
    "        #clean up\n",
    "        min_SNR = 3            # adaptive way to set threshold on the transient size\n",
    "        r_values_min = 0.85    # threshold on space consistency (if you lower more components\n",
    "        #                        will be accepted, potentially with worst quality)\n",
    "        cnm.params.set('quality', {'min_SNR': min_SNR,\n",
    "                                   'rval_thr': r_values_min,\n",
    "                                   'use_cnn': False})\n",
    "\n",
    "        cnm.estimates.evaluate_components(Y, cnm.params)\n",
    "\n",
    "        print(' ***** ')\n",
    "        print('Number of total components: ', len(cnm.estimates.C))\n",
    "        print('Number of accepted components: ', len(cnm.estimates.idx_components))\n",
    "\n",
    "        idx = cnm.estimates.idx_components\n",
    "\n",
    "        cnm_idx_fn = 'cnm_idx_key' + post_str\n",
    "        np.save(os.path.join(analysis_dir, cnm_idx_fn), idx)\n",
    "    except:\n",
    "        print('Error in', key)\n",
    "        f.write('\\nError in key ' + str(key))\n",
    "        f.close()\n",
    "        if 'dview' in locals():\n",
    "            cm.stop_server(dview=dview)\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
